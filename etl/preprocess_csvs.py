import pandas as pd
import numpy as np
from helpers.parsers import parse_categoricals, parse_datetime, parse_int
from etl.feature_engeneering import clean_df, create_distance_col, create_y_col

def preprocess_csvs(urls: list, aerodromos: pd.DataFrame) -> pd.DataFrame:
    """
    Carrega, filtra e preprocessa m√∫ltiplos arquivos CSV do VRA (Voo Regular Ativo) 
    disponibilizados pela ANAC, retornando um √∫nico DataFrame consolidado.

    Este procedimento realiza o download sequencial dos arquivos, aplica regras de ETL 
    para limpeza e normaliza√ß√£o dos dados e concatena os resultados em um DataFrame √∫nico. 
    Ao final, os dados retornados cont√™m apenas informa√ß√µes relevantes para an√°lise de 
    voos realizados, com colunas categ√≥ricas otimizadas e datas convertidas para datetime.

    Etapas executadas para cada arquivo CSV:
        1. Download e leitura do arquivo bruto, ignorando as duas primeiras linhas 
           (‚ÄúAtualizado em‚Äù e o cabe√ßalho original).
        2. Sele√ß√£o das colunas necess√°rias conforme o layout oficial da ANAC.
        3. Remo√ß√£o de linhas cuja situa√ß√£o do voo seja "CANCELADO".
        4. Remo√ß√£o de registros com valores ausentes nas colunas de data/hora.
        5. Convers√£o das colunas de data para o tipo datetime.
        6. Convers√£o de colunas categ√≥ricas para o tipo category (otimiza√ß√£o de mem√≥ria).
        7. Concatena√ß√£o incremental no DataFrame mestre.

    Par√¢metros
    ----------
    urls : list
        Lista contendo as URLs dos arquivos CSV a serem processados.
    aerodromos : pd.DataFrame
        DataFrame contendo informa√ß√µes sobre aer√≥dromos da ANAC.

    Retorno
    -------
    pandas.DataFrame
        DataFrame consolidado contendo apenas voos realizados e colunas previamente 
        definidas, com tipagem otimizada e datas convertidas.

    Observa√ß√µes
    -----------
    - A fun√ß√£o imprime estat√≠sticas de progresso, quantidade de linhas carregadas 
      e uso de mem√≥ria ao longo do processo.
    """

    print(f"Iniciando o download e preprocessamento de {len(urls)} arquivos CSV...\n")

    # Colunas do CSV original disponibilizado pela ANAC
    raw_columns = [
        "Empresa A√©rea",
        "N√∫mero Voo",
        "C√≥digo Autoriza√ß√£o (DI)",
        "C√≥digo Tipo Linha",
        "Aer√≥dromo Origem",
        "Aer√≥dromo Destino",
        "Partida Prevista",
        "Partida Real",
        "Chegada Prevista",
        "Chegada Real",
        "Situa√ß√£o Voo",
        "C√≥digo Justificativa"
    ]

    # Colunas desejadas
    columns = [
        "Empresa A√©rea",
        "Aer√≥dromo Origem",
        "Aer√≥dromo Destino",
        "Partida Prevista",
        "Partida Real",
    ] 

    # Inicializa o DataFrame mestre
    master_df = pd.DataFrame()

    # Inicializa lista para armazenar DataFrames individuais
    dfs = []

    # Vari√°veis de controle
    lines = 0
    memory_usage = 0

    for i, url in enumerate(urls, start=1):

        print(f"[{i}/{len(urls)}] Carregando: {url.replace('https://sistemas.anac.gov.br/dadosabertos/Voos%20e%20opera%C3%A7%C3%B5es%20a%C3%A9reas/Voo%20Regular%20Ativo%20%28VRA%29', 'http://...')}")

        try:
            # Leitura do CSV bruto
            df = pd.read_csv(
                url,
                sep=';',
                quotechar='"',
                skiprows=2,         # pula "Atualizado em" + header
                header=None,
                names=raw_columns,
                low_memory=False
            )

        except Exception as e:
            print(f"‚ùå Falha ao ler {url}\nErro: {e}")
            continue

        if df.empty:
            print(f"‚ö†Ô∏è CSV vazio em {url}, ignorando.")
            continue

        # Limpeza de dados
        df = clean_df(df, aerodromos=aerodromos, columns=columns)

        # Engenharia de Features
        df = create_distance_col(df, aerodromos=aerodromos)
        df = create_y_col(df)

        # Parsing de tipos de dados
        df = parse_categoricals(df)
        df = parse_datetime(df)
        df = parse_int(df, col="Dist√¢ncia (m)", int_type='int32')

        # Adiciona o df limpo √† lista
        dfs.append(df)

        lines += df.shape[0]
        memory_usage += df.memory_usage(deep=True).sum() / (1024 ** 2)
        print(f"‚úî {df.shape[0]} linhas carregadas.")
        print(f"   Total atual de linhas: {lines}")
        print(f"   Mem√≥ria usada: {memory_usage:.2f} MB\n")

    # Concatena todos os dfs ao DataFrame mestre
    master_df = pd.concat(dfs, ignore_index=True)

    print(f"\nüèÅ Finalizado.\n")
    print(f"Total de linhas carregadas: {master_df.shape[0]}")
    print(f"Mem√≥ria usada no Dataframe Master: {master_df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\n")

    return master_df